# 🧠 iNLP Lab Reading Groups  

Welcome to the **inclusive NLP (iNLP) Group** at SUTD!  

We are a research group dedicated to advancing **Natural Language Processing** (NLP) and Large Language Models (LLMs), with a strong focus on making AI inclusive, trustworthy, and safe through research on alignment and human-centered design.

Our reading groups welcome not only internal members but also **external guests**. The goal is to foster collaboration, exchange ideas, and make our research community more open and inclusive.  

👉 **External guests are welcome to attend and present!** If you’d like to join us or give a talk, please reach out.  

---

## 📅 Upcoming & Past Meetings (2025)

| Date       | Presenter       | Topic                                               | Slides |
|------------|----------------|----------------------------------------------------|--------|
| 20/08/2025  | Long P. Hoang  | A Discussion about GPT-OSS and GPT-5               | [Slides](https://isaac-lab.sg.larksuite.com/slides/RFULsHrq0lffkMdKennlShiSgki?from=from_copylink) |
| 27/08/2025 | Rishabh        | On Red Teaming and Safety (Re)-Alignment of LLMs   | [Slides](2.%20Rishabh-SUTD-NLP-LAB_27Aug25.pdf) |
| 03/09/2025  | Chen Huang     | Scope and Effect of RL techniques on LLMs          | [Slides](https://isaac-lab.sg.larksuite.com/slides/Ibs9sBQMSlphIfdj2Mnl963Kg6d?from=from_copylink) |
| 18/09/2025  | Ryner Tan    |           |  |
---

## 🎯 Why Join Us?

- 🌍 Learn about cutting-edge NLP & AI research.  
- 🤝 Meet researchers from academia & industry.  
- 🧩 Discuss technical, ethical, and societal challenges of LLMs.  
- 🚀 Build collaborations in inclusive and open AI.  

---

## 📍 Logistics

- **When**: Weekly or Bi-Weekly (usually Thursdays 10.30am - 12pm).  
- **Where**: Hybrid (SUTD campus + online Ms Teams link).  

---

## 🌟 About iNLP Lab

The inclusive NLP (iNLP) Lab at SUTD is dedicated to advancing the next generation of Natural Language Processing (NLP) systems that are not only powerful, but also inclusive and trustworthy.
- Inclusive → We design models that support diverse languages, cultures, and users. This includes research on multilingual LLMs, accessibility through efficient and compressed models, and human-centered design for broader adoption.
- Trustworthy → We ensure that NLP systems are safe, robust, and reliable across settings. Our work includes LLM safety frameworks, fair and comprehensive evaluation, and mechanistic studies to better understand *knowledge and reasoning inside LLMs.
- NLP at large → Beyond application-driven projects, we pursue fundamental questions in machine learning and language modeling, exploring how models represent, reason, and interact with humans.

---